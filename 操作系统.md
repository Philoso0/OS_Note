---
dg-publish: "true"
dg-home: "true"
---
# 1 基本概念
## 现代操作系统的主要特征
微内核、多线程、对称多处理、分布式操作系统、面向对象设计
## 5状态模型和7状态模型，7状态的优势
5状态：就绪态、运行态、阻塞态、新建态、退出态
7状态：就绪态、运行态、阻塞态、新建态、退出态、就绪/挂起、阻塞/挂起
**主要优势**：
1. 增加了就绪挂起和阻塞挂起两个状态，可以有效地进行操作系统的中层调度，便于实现多道程序设计
2. 两个挂起态可以有效缓解内存不足的问题

-----

1. 更高效的内存资源管理。允许操作系统将长时间不活动的进程移到磁盘，释放物理内存。这使得系统可以容纳更多的进程，提升了内存的利用率。
2. 更细致的进程调度。系统能够集中资源调度那些更活跃的、等待CPU的就绪进程，从而优化整体的调度效率。这使得操作系统在切换和调度时能够更精准地判断每个进程的需求，提高了系统对高优先级进程的响应速度。
3. 减少不必要的进程切换。允许系统将这些长时间阻塞的进程转移到**阻塞/挂起**状态，从而将资源集中于那些可能会更快恢复的进程。这种改进减少了对阻塞进程的频繁检查和不必要的切换开销，从而提高了CPU的使用效率，减少了系统开销。
4. 更适应复杂多任务环境。对于需要频繁切换任务的复杂应用场景，七状态模型能够有效区分进程的优先级和状态，提供更加流畅的并发处理效果。
## 进程状态切换步骤
1. 保存处理器上下文，包括程序计数器PC和其他寄存器
2. 更新当前处于运行态的进程的PCB
3. 将PCB移动到相应的队列（就绪、阻塞、就绪/挂起）
4. 选择另一个进程执行
5. 更新所选进程的PCB
6. 更新内存管理数据结构
7. 恢复被选进程的上下文信息
## 用户级线程相对于内核级线程的两个缺点
1. 用户级线程会引起阻塞
2. 纯粹的用户级线程策略不能利用多处理器技术
**用户级线程的缺点**
1. **缺乏并行执行能力**：
	1. 在大多数操作系统中，用户级线程是由用户态库来管理的，而操作系统内核仅将整个进程视为一个执行单元。
	2. 因此，即便一个进程内存在多个用户级线程，操作系统也只会分配一个CPU给该进程，所有线程必须在单个CPU上运行，无法在多核处理器上实现真正的并行执行。
2. **线程阻塞问题**：
	1. 如果一个用户级线程执行了阻塞操作（如I/O），整个进程都会被阻塞，因为操作系统内核无法识别和调度其他用户级线程来继续运行。
	2. 这会导致其他线程必须等待，影响系统的整体效率。
3. **缺乏内核支持**：
	1. 用户级线程缺乏操作系统的直接管理和调度支持，所有线程调度和切换均由用户态库完成。虽然这样开销较小，但调度策略较为简单且灵活性较低，不适合高并发环境。
4. **不支持多线程的优先级管理**：
	1. 用户级线程无法享受内核级线程的优先级调度，所有线程由库函数进行简单调度，无法根据优先级动态分配CPU资源。
**内核级线程的缺点**
1. **切换开销大**
	1. 内核级线程的调度由操作系统内核完成，线程切换时需要经过内核态和用户态的上下文切换，增加了线程切换的系统开销。
	2. 尤其是在频繁切换的高并发场景下，频繁进入内核态导致的开销会降低性能。
2. **占用更多资源**：
	1. 每个内核级线程都需要操作系统的直接管理，操作系统会为每个线程分配一个线程控制块（TCB）等资源，导致系统资源消耗更大。
	2. 在大量线程并发时，内核管理开销和资源占用较高，可能导致系统响应变慢。
3. **不够灵活**：
	1. 内核级线程的调度策略由操作系统统一管理，用户无法在应用层自定义调度策略和线程管理细节。
	2. 当应用需要特定的调度策略或对线程切换有独特需求时，内核级线程的可控性较低。
4. **依赖内核的支持**：
	1. 内核级线程的实现依赖操作系统内核的支持，移植性相对较差。如果操作系统不支持多线程或多核处理，内核级线程的功能就无法实现。

| 线程类型  | 缺点                                   |
| ----- | ------------------------------------ |
| 用户级线程 | 缺乏并行执行能力；阻塞操作会阻塞整个进程；缺少内核支持；不支持优先级管理 |
| 内核级线程 | 切换开销大；占用更多系统资源；不够灵活；依赖操作系统内核的支持      |
## 死锁发生的三个必要条件
互斥、不剥夺、占有并请求、循环等待链
# 2 进程与线程
## 2.1 进程
### 2.1.1 五状态进程
创建、就绪、运行、阻塞、退出
![[进程5状态模型.png]]

### 2.1.2 进程控制
#### 进程切换
进程切换时进程控制的主要工作内容

>[!info] 原语
>原语是一种特殊的程序，它的执行具有原子性，这段程序运行必须一气呵成不可中断。
>否则，就有可能导致操作系统中某些关键数据结构信息不统一的情况，这会影响操作系统进行别的管理工作。
>原语的原子性通过“开/关中断指令”这两个特权指令实现。

寄存器
PSW：程序状态字寄存器
PC：程序计数器，存放下一条指令的地址
IR：指令寄存器，存放当前正在执行的指令
通用寄存器：其他的必要信息
#### 进程通信（Inter-Process Communication, IPC）
两个进程之间产生的数据交互
进程是分配系统资源的单位（包括内存地址空间），因此各进程拥有的内存地址空间相互独立

三种IPC机制
- 共享存储
	- 发起通讯请求的进程会申请一块共享存储
	- 共享存储区可以被多个进程访问
	- 通过增加页表项/段表项实现，即可将同一块共享内存区映射到各个进程的地址空间中 
	- 需要保证各个进程对共享内存的访问是互斥的
	- 实现方式：
		- 基于存储区的共享：操作系统在内存中划出一块共享存储区，数据的形式、存放位置都由通信进程控制，而不是操作系统。这种共享方式速度很快，是一种高级通信方式
		- 基于数据结构的共享：比如只能存放一个长度为10的数组，这种共享方式速度慢，限制多，是一种低级存储方式
- 消息传递
	- 进程间的数据交换以格式化的message为单位。进程通过操作系统提供的“发送/接收消息”两个原语进行数据交换
	- 消息结构
		- 消息头：包括发送进程ID、接受进程ID、消息长度等格式化信息
		- 消息体
	- 消息传递方式
		- 直接通信方式：要指明接受进程的ID
		- 间接通信方式：通过“信箱”间接地通信，又称“信箱通信方式”
- 管道通信（Pipe）
	- Pipe是一个特殊的共享文件，是在内存中开辟一块大小固定的内存缓冲区，从数据结构的角度看，Pipe是一个循环队列
	- 管道只能采用**半双工通信**，某一事件段内只能实现单向的传输，且遵循FIFO的优先级。如果需要双向同时通信，则要设置两个管道。
	- 各进程需要**互斥**地访问管道
	- 当管道写满，写进程将阻塞，直到读进程将管道中的数据读走，即可唤醒写进程
	- 当管道读空，读进程将阻塞，直到写进程往管道中写入数据，即可唤醒读进程
	- 管道中的数据一旦被读出，就彻底消失。因此，当多个进程读同一个管道时可能会错乱。解决方案：
		- 一个管道允许多个写进程，一个读进程
		- 允许多个写进程，多个读进程，但系统会让各个读进程轮流从管道中读数据（Linux方案）
### 2.1.3 操作系统和用户进程之间的关系
1. 无进程的内核
	1. 在所有进程之外执行操作系统内核
	2. 操作系统代码作为一个单独实体运行在特权模式
2. 在用户进程中执行
	1. 在用户进程的上下文中执行操作系统软件
	2. 当执行到操作系统代码时，进程进入特权模式
	3. 无需进程切换，只需模式切换
3. 基于进程的操作系统
	1. 操作系统作为一组系统进程来实现
	2. 模块化操作系统
	3. 在多处理器和多机的环境中十分有用

## 2.2 线程
在没有引入进程之前，系统中各个程序只能串行执行。进程是程序的一次执行，但是这些功能显然不可能由一个程序处理就能实现。有的进程需要并行执行多道程序。为此，引入了“线程”，增加并发度。
线程某种程度上是“轻量级进程”。一个进程中可以有多个线程来增加并发度，使得一个进程内也可以并发地处理多种任务，此时**线程成为了CPU的最小执行单元**。不同线程可以执行不同或相同的代码。引入线程后，进程只作为除CPU外的系统资源的分配单元，资源是分配给进程而非线程。

- 资源分配、调度
	- 传统进程机制中，进程是资源分配、调度的基本单位
	- 引入线程后，进程是资源分配的基本单位，线程是调度的基本单位
- 并发性
	- 传统进程机制中，只能进程间并发
	- 引入线程后，各线程间也可以并发，提升了并发度
- 系统开销
	- 传统的进程间并发，需要切换进程的运行环境，系统开销大
	- 线程间并发，如果是同一进程内的线程切换，则无需切换进程环境，系统开销小
	- 引入线程后，并发所带来的系统开销减小
		- 线程是处理机调度的单位
		- 多CPU计算机中，各个线程可以占用不同的CPU
		- 每个线程都有一个线程ID、线程控制块TCB
		- 线程也有就绪、阻塞、运行三种基本状态
		- 线程几乎不拥有系统资源
		- 同一进程的不同线程共享进程的资源。由于共享内存地址空间，同一进程中的线程间通信甚至无需系统干预
		- 同一进程中的线程切换不会引起进程切换；不同进程的线程切换会引起进程

### 2.2.1 线程的实现方式
![[用户级线程和内核级线程模型.png]]
#### 用户级线程 User-Level Thread
- 用户级线程由应用程序通过线程库实现，所有的**线程切换工作**都由**应用程序负责实现**（包括线程切换）
- 用户级线程中，线程切换在**用户态下即可完成**，无需操作系统干预
- 在用户看来，是有多个线程；但是在操作系统内核看来，并意识不到线程的存在。“用户级线程”就是“从用户视角看能看到线程”
- 优缺点
	- 优点：用户级线程的切换可以在用户空间即可完成，不需要切换到核心态，线程管理的系统开销小，效率高
	- 缺点：当一个用户级线程被阻塞，整个进程都会被阻塞，并发度不高。多个线程不可以在多核处理机上并发运行，因为内核还是以进程为调度的最小单位分配CPU时间，一个进程只能被分配一个核心。
#### 内核级线程 Kernel-Level Thread
- 内核级线程是由操作系统支持的线程
- 内核级线程的管理工作由CPU内核完成
- 线程调度、切换等工作都由内核负责，因此**内核级线程的切换**必须要在**核心态**下才能完成
- 操作系统会为每个内核级线程建立相应的TCB，通过TCB对线程进行管理。“内核级线程”就是“从操作系统内核视角能看到线程”
- 优缺点
	- 优点：当一个线程被阻塞后，别的线程还可以继续执行，并发能力强。多线程可以在多核处理机上并发执行
	- 缺点：一个用户进程会占用多个内核级线程，线程切换由操作系统内核完成，需要由用户态切换到核心态，因此线程管理成本高，开销大。
#### 多线程模型
![[多线程模型.png]]
- 在支持内核级线程的系统中，根据用户级线程和内核级线程的映射关系，可以划分几种多线程模型
	- 一对一：一个用户级线程映射到一个内核级线程。每个用户进程有与用户级线程同数量的内核级线程。即内核级线程模型。
		- 优点：当一个线程被阻塞之后，别的线程还可以继续执行，并发能力强。多线程可以在多核处理机上并行执行
		- 缺点：一个用户进程会占用多个内核级线程，线程切换由操作系统内核完成，需要由用户态切换到核心态，因此线程管理成本高，开销大。
	- 多对一：多个用户级线程映射到一个内核级线程。且一个进程只被分配一个内核级线程。即用户级线程模型。
		- 优点：用户级线程的切换可以在用户空间即可完成，不需要切换到核心态，线程管理的系统开销小，效率高
		- 缺点：当一个用户级线程被阻塞，整个进程都会被阻塞，并发度不高。多个线程不可以在多核处理机上并发运行，因为内核还是以进程为调度的最小单位分配CPU时间，一个进程只能被分配一个核心。
		- 操作系统只“看得见”内核级线程，因此只有内核级线程才是处理机分配的单位。
	- 多对多：$n$用户及线程映射到$m$个内核级线程$(n\geq m)$。每个用户进程对应$m$个内核级线程
		- 优点：克服了多对一模型并发度不高的缺点（一个阻塞全体阻塞），又克服了一对一模型中一个用户级线程占用太多内核级线程，开销太大的缺点

- ULT是“代码逻辑”的载体
- KLT是“运行机会”的载体
	- **内核级线程才是处理机分配的单位**
- 一段“代码逻辑”只有获得了“运行机会”才能被CPU执行
	- 内核级线程中可以运行任意一个有映射关系的用户级线程代码，只有所有内核级线程中正在运行的代码逻辑都阻塞，这个进程才会阻塞

### 2.2.2 线程的状态与转换、组织与控制
![[TCB的结构.png]]
堆栈指针通常会被分配到堆栈寄存器SP中

线程的组织就是按照某种规则将TCB形成一张线程表，可以一个进程中的所有线程存成一张线程表；可以系统中所有线程存储到一张线程表；也可以相同状态的线程存储到同一张线程表等

## 2.3 处理机调度
### 2.3.1 调度的基本概念
由于资源有限，很多工作无法同时处理，必须要某种规则来决定处理任务的顺序
### 2.3.3 调度的三个层次
#### 高级调度-作业调度
内存的空间有限，有时无法将用户提交的所有作业全部放入内存。按照一定的原则从外存的作业后备队列中挑选一个作业调入内存，并创建进程。每个作业只调入一次，建立PCB，调出一次，撤销PCB。
#### 低级调度-进程调度/处理机调度
按照某种策略从就绪队列中选取一个进程，将处理机分配给它。
进程调度是操作系统中最基本的一种调度，在一般的操作系统中都必须配置进程调度。进程调度的频率很高，一般几十毫秒一次。
#### 中级调度-内存调度
内存不足时，可将某些进程的数据调到外存。等内存空闲或者进程需要运行时再重新调入内存。
暂时调到外存等待的进程状态为**挂起状态**，被挂起的进程PCB会被组织成**挂起队列**
中级调度（内存调度）就是按照某种策略决定将哪个处于挂起状态的进程重新调入内存

|      | 调度发生地点       | 发生频率 | 对进程状态的影响             |
| ---- | ------------ | ---- | -------------------- |
| 高级调度 | 外存->内存（面向作业） | 最低   | 无->创建态->就绪态          |
| 中级调度 | 外存->内存（面向进程） | 中等   | 挂起态->就绪态（阻塞/挂起->阻塞态） |
| 低级调度 | 内存->CPU      | 最高   | 就绪态->运行态             |

### 2.3.3 七状态模型
创建、就绪、运行、阻塞、退出、就绪/挂起、阻塞/挂起
- 创建
	- 可执行文件从外存调入内存，同时操作系统为其创建一个PCB，即进程，这个阶段操作系统会为其分配资源，初始化PCB
- 就绪
	- 已经准备好执行但是CPU此时没空
	- 系统中可能同时存在多个处于就绪态的进程，当CPU空闲时，操作系统就会按某种策略选择一个进行执行
- 阻塞
	- 在运行过程中，可能会请求等待某个事件的发生（如等待系统资源的分配，或等待其他进程的相应）
	- 当等待事件发生时，进程会回到就绪态，等待CPU空闲
- 终止
	- 进程执行`exit`系统调用，请求操作系统终止该进程。此时操作系统会让其下CPU并回收内存空间等资源，最后回收PCB
挂起：suspend
![[进程7状态模型.png]]
主要优势：
1. 增加了两种suspend状态可以有效进行操作系统的中层调度，控制多道程序设计的调度
2. 两个挂起态可以释放内存空间，缓解内存不足的问题
### 2.3.4 进程调度的时机
- **需要**进行进程调度与切换的情况
	- 主动放弃
		- 进程正常终止
		- 运行过程中发生异常而终止
		- 进程主动请求阻塞（等待I/O等）
	- 被动放弃
		- 分给进程的时间片用完
		- 有更加紧急的事需要处理（如I/O中断）
		- 有更高优先级的进程进入就绪队列
- **不能**进行进程调度与切换的情况
	- 在处理中断的过程中。中断处理过程复杂，与硬件密切相关，很难做到在中断处理过程中进行进程切换
	- 进程在操作系统内核程序临界区中
		- 内核程序临界区一般是用来访问某种内核数据结构的，比如进程的就绪队列。进程在访问内核临界区时，会给访问的临界资源上锁，如果不尽快释放极有可能影响到操作系统内核的其他管理工作。因此在访问内核程序临界区期间不能进行调度与切换
	- 在原子操作过程中（原语）。原子操作不可中断，要一气呵成
### 2.3.5 进程调度的方式
- **非剥夺调度/非抢占方式** 只允许进程主动放弃处理机。在运行过程中即便有更紧迫的任务到达，当前进程依然会继续使用处理机，直到该进程终止或者主动要求进入阻塞态。
	- 系统开销小，但是无法及时处理紧急任务，适合于早期的批处理系统
- **剥夺调度/抢占方式** 当一个进程在处理机上执行时，如果有一个更加重要或更紧迫的进程需要使用处理机，则立即停止正在执行的进程，将处理机分配给更重要紧迫的进程
	- 可以优先处理更紧急的进程，也可以让各进程按照时间片轮流执行的功能（通过时钟中断）。适合粉饰操作系统、实时操作系统
### 2.3.6 进程的切换与过程
- **狭义的进程调度**是指从就绪队列中**选中一个要运行的进程**（这个进程可以是刚刚被暂停执行的进程，也可以是另一个进程，后一种情况需要进程切换）。
- **进程切换**是指一个进程让出处理机，由另一个进程占用处理机的过程。
- **广义的进程调度**包含了选择一个进程和进程切换两个步骤

进程切换主要完成了：
1. 对原来运行进程各种数据的保存
2. 对新的进程的各种数据的恢复
	1. 如程序计数器PC、程序状态字、各种数据寄存器等处理机现场信息，这些信息一般保存在PCB
3. **进程切换是有代价的**，如果过于频繁地进行进程调度、切换，必然会使整个系统的效率降低，是系统大部分时间都花在了进程切换上，而真正用于执行进程的时间减少

**进程切换步骤**
1. 保存处理器上下文，包括程序计数器和其他寄存器
2. 更新当前处于运行态的进程的PCB（Process Ctrl Blocks）
3. 将PCB移至相应的队列（ready, blocked or ready/suspend）
4. 选择另一个进程执行
5. 更新所选进程的PCB
6. 恢复内存管理数据结构
7. 恢复被选进程的上下文信息
#### 调度器/调度程序 scheduler
- 调度时机
	- 创建新进程
	- 进程退出
	- 运行进程阻塞
	- I/O中断发生
- 非抢占式调度只有运行阻塞或退出才触发调度程序工作
- 抢占式调度策略每个时钟中断或者每k个时钟中断会触发调度程序工作
- 不支持内核级线程的OS的调度程序的处理对象是进程；支持内核级线程的OS的调度程序处理对象是内核线程
#### 闲逛进程 idle
CPU永远不会停工，如果没有其他就绪进程时，就会运行闲逛进程idle
闲逛进程特性
- 优先级最低
- 可以是0地址指令，占一个完整的指令周期（指令周期末尾例行检查中断）
- 能耗低
### 2.3.7 调度算法
#### 调度算法的评价指标
- **CPU利用率**：CPU忙碌时间占总时间的比例
- **系统吞吐量**：
$$
\text{系统吞吐量}=\frac{\text{总共完成多少道作业}}{\text{总共花费多少时间}}
$$
- **周转时间**：作业被提交给系统开始，到作业完成为止的这段时间间隔
	- 作业在外存后备队列上等待作业调度（高级调度）的时间
	- 进程在就绪队列上等待进程调度（低级调度）的时间
	- 进程在CPU上执行的时间
	- 进程等待I/O操作完成的时间。
	- 后三项在一个作业的整个处理过程中可能多次发生
	- **作业周转时间**=作业完成时间-作业提交时间
	- **平均周转时间**=各作业周转时间之和/作业数
	- **带权周转时间**=作业持续时间/作业实际运行时间，对于周转时间相同的两个作业，实际运行时间长的作业在相同时间内被服务的时间更多，带权周转时间更小，用户满意度更高
	- **平局带权周转时间**
- **等待时间**：指进程/作业处于等待处理机状态的时间之和
	- 进程在等待I/O处理过程的时间不计入等待时间，因为此时认为进程是被I/O设备服务的
- **响应时间**：从用户提交请求到首次产生响应所用时间
#### 先来先服务 FCFS
- 算法思想：主要从“公平”的角度考虑
- 算法规则：按照作业/进程到达的先后顺序进行服务
- 用于作业/进程调度：
	- 用于作业调度时，考虑哪个作业先到达后备队列
	- 用于进程调度时，考虑哪个进程先到达就绪队列
- 非抢占式算法
- 优点：公平、算法实现简单
- 缺点：排在长作业/进程后面的短作业需要等待很长时间，带权周转时间很大，对短作业来说用户体验差。即该算法对长作业有利，对短作业不利
- 不会导致饥饿
#### 短作业优先 SJF
- 算法思想：追求最少的平均等待时间，最少的平均周转时间，最少的平均带权周转时间
- 算法规则：每次调度选择当前已到达且运行时间最短的作业/进程优先得到服务（指要求的服务时间最短）
- 用于作业/进程调度：
	- 用于作业调度时，称为SJF，Shortest Job First
	- 用于进程调度时，称为SPF，Shortest Process First
- 非抢占式算法
	- SJF和SPF是非抢占式的算法。
	- 但是也有抢占式的版本——最短剩余时间优先算法（SRTN,Shortest Remaining Time Next），该算法的周转时间系列指标会更优
- 优点：平均等待时间、平均周转时间最少
- 缺点：不公平。对短作业有利，对长作业不利。可能导致饥饿现象。另外，作业/进程的运行时间是由用户提供的估计值，并不一定真实，不一定能做到真正的短作业优先
- 可能会导致饥饿，如果源源不断有短作业/进程到来，长作业/进程长时间得不到服务，产生饥饿现象。如果一直得不到服务，则称为“饿死”
#### 高响应比优先 HRRN
- 算法思想：综合考虑作业/进程的等待时间和要求服务的时间
- 算法规则：
	- 每次调度时计算各个作业/进程的响应比，选择响应比最高的作业/进程服务
	- 响应比=（等待时间+要求服务的时间）/要求服务的时间
- 用于作业/进程调度：
	- 可用于作业调度和进程调度
- 非抢占式算法
	- 只有当前运行的作业/进程主动放弃处理机，才需要调度，重新计算响应比
- 优点
	- 综合考虑了等待时间和运行时间（要求服务时间）
	- 等待时间相同时，要求服务时间短的优先（SJF的优点）
	- 要求服务时间相同时，等待时间长的优先（FCFS的优点）
	- 对于长作业/进程来说，随着等待时间越来越久，其响应比也会越来越大，从而避免了长作业/进程饥饿的问题
- 不会导致饥饿
#### 时间片轮转 RR Round Robin
- 算法思想：公平地、轮流的为各个进程服务，让每个进程在一定时间间隔内都可以得到响应
- 算法规则：按照各进程到达就绪队列的顺序，轮流地让各个进程执行一个时间片100ms。若进程未在一个时间片内执行完成，则剥夺处理机，将进程重新放入就绪队列队尾排队
- 用于进程调度（只用作业放入内存建立了相应的进程后，才能被分配处理机时间片）
- 若进程没能在时间片内完成，将强行剥夺处理机使用权，因此属于抢占式算法。由时钟装置发出时钟中断来通知CPU时间片结束
- 优点：公平；响应快，适用于分时操作系统
- 缺点：由于高频率的进程切换，因此有一定开销；不区分任务的紧急程度
- 不会导致饥饿
#### 优先级调度
- 算法思想：实时操作系统的出现，越来越多的应用场景需要根据任务的紧急程度来决定处理顺序
- 算法规则：每个作业/进程有各自的优先级，调度时选择优先级最高的作业/进程
- 可用于作业/进程调度，还会用于I/O调度
- 抢占式非抢占式都有。非抢占式只需要在进程主动放弃处理机时进行调度即可，而抢占式还需要在就绪队列变化时，检查是否会发生抢占
- 就绪队列未必只有一个，可以按照不同优先级组织
- 根据优先级是否可以动态改变，可以将优先级分为静态/动态优先级两种
	- 静态优先级：创建进程时确定，之后不变
	- 动态优先级：创建进程时有一个初始值，之后根据情况动态地更新优先级
- 特点
	- 系统进程优先级高于用户进程
	- 前台进程优先级高于后台进程
	- 操作系统更偏好I/O型进程（I/O繁忙型，对应CPU繁忙型）
		- I/O设备可以和CPU设备并行工作，如果优先让I/O设备繁忙型进程优先运行，则越有可能让I/O设备尽早投入工作，则资源利用率和系统吞吐量都会提高
	- 优点：可以区分紧急程度、重要程度，适用于实时操作系统，可以灵活地调整各种作业/进程的偏好程度
	- 缺点：若源源不断地有高优先级进程到来，则可能导致饥饿
- 会导致饥饿
#### 多级反馈队列调度
- 算法思想：对其他调度算法的折中权衡
- 算法规则
	- 设置多级就绪队列，各级队列优先级从高到低，时间片从小到大
	- 新进程到达时先进入1级队列，按FCFS原则排队等待被分配时间片；若用完时间片进程还未结束，则进程进入下一级队列队尾；如果此时已经是在最下级的队列，则重新放回该队列队尾
	- 只有第k级队列为空时，才会为k+1级对头的进程分配时间片
- 用于进程调度
- 抢占式的算法。在k级队列的进程运行过程中，若更上级($1\sim k-1$)的队列中进入了一个新进程，则由于新进程的优先级更高，会抢占处理机，原来运行的进程放回k级队列的队尾
- 优点
	- 对各类进程相对公平FCFS
	- 每个新到达的进程都可以很快得到响应RR
	- 短进程只用较少的时间就可以完成SPF
	- 不必实现估计进程的运行时间，避免用户作假
	- 可灵活地调整对各类进程的偏好程度
- 会导致饥饿

后三种调度算法适合交互式系统
## 2.4 进程的同步和互斥
### 2.4.1 进程同步、互斥的基本概念
进程具有异步性的特征，即各并发执行的进程以各自独立的、不可预知的速度向前推进。
**同步**亦称**直接制约关系**，是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而产生的制约关系。进程间的直接制约关系源于他们之间的相互合作

进程的**并发**需要**共享**的支持。各个并发执行的进程不可避免的需要共享一些系统资源（比如内存，或打印机、摄像头这样的I/O设备）

**临界资源**：一个时间段内只允许一个进程使用的资源称为临界资源
**对临界资源的访问必须互斥地进行**。互斥，亦称**间接制约关系**。进程互斥指当一个进程访问某些临界资源时，另一个想要访问该临界资源的进程必须等待，直到当前访问临界资源的进程访问结束，释放该资源之后，另一个进程才能去访问临界资源。

对临界资源的互斥访问，可以在逻辑上分为如下四个部分：
```C
do{
	entry section;    //进入区
	critical section; //临界区 访问临界资源的那一段代码
	exit section;     //退出区
	remainder section;//剩余区
}while(true)
```
- 进入区
	- 负责检查是否可以进入临界区，若可以进入，则应设置“正在访问临界资源的标志”（上锁），以防止其他进程同时进入临界区
- 临界区
	- 访问临界资源的那段代码
- 退出区
	- 负责解除“正在访问临界资源的标志”（解锁）
- 剩余区
	- 其他处理
- **临界区**是进程中访问临界资源的代码段，临界区也可称为临界段。
- **进入区**和**退出区**是**负责实现互斥**的代码段。

进程互斥需要遵循以下原则：
1. **空闲让进**。临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区
2. **忙则等待**。当已有进程进入临界区时，其他试图进入临界区的进程必须等待
3. **有限等待**。对请求访问的进程，应保证能在有限时间内进入临界区（保证不会饥饿）
4. **让权等待**。当进程不能计入临界区时，应该立即释放处理机，防止进程忙等待
### 2.4.2 进程互斥的实现方法
#### 2.4.2.1 进程互斥的软件实现方法
#### 2.4.2.2 进程互斥的硬件实现方法
#### 2.4.2.3 进程互斥的信号量机制实现方法
##### 互斥锁 Mutex Lock
互斥锁是解决临界区的最简单的工具。
每个互斥锁有一个`bool`变量`available`，表示锁是否可用。如果锁是可用的`acquire()`，会成功，且锁不再可用。当一个进程试图获取不可用的锁时，会被阻塞，直到锁被释放。
```C++
acquire(){
	while(!available)
		...;        //忙等待
	available=false;//获得锁
}
release(){
	available=true; //释放锁
}
```
`acquire()`和`release()`必须是原子操作，因此互斥锁通常采用硬件机制实现。
互斥锁的主要缺点是**忙等待**，当有一个进程在临界区中，其他任何进程在进入临界区时必须循环调用`acquire()`。当多个进程共享同一CPU时，就浪费了CPU周期。因此，互斥锁通常用于多处理器系统，一个线程在某个处理器上等待不影响其他线程的执行。
需要连续循环忙等的互斥锁，称为**自旋锁**，如TSL指令、swap指令、单标识法

特性：
- 需要忙等，进程时间片用完才能下处理机，违反“让权等待”
- 优点：等待期间不用切换进程上下文，多处理器系统中，若上锁时间短，则等待代价很低
- 常用于多处理器系统，一个核忙等，其他核正常工作，并快速释放临界区
- 不适用单处理机系统，忙等过程中不可能解锁
##### 信号量机制 Semaphore
用户进程可以通过使用操作系统提供的**一对原语**来对**信号量**进行操作，从而很方便地实现了进程互斥
**信号量**就是一个变量（可以是整数也可以是更复杂的记录型变量），可以用一个信号量来表示系统中的某种资源的数量。
**一对原语** `wait(S)`和`signal(S)`，括号里的**信号量S**相当于函数调用时传入的参数
`wait`,`signal`原语简称“P、V”操作（荷兰语proberen、verhogen）。因此，`wait(S)`和`signal(S)`可写作`P(S)`和`V(S)`

```C++
int S = 1;            //初始化整型信号量S，表示系统可用打印机资源数量
void wait (int S) {   //wait 原语，相当于“进入区”
	while (S <= 0);   //如果资源数不够，一直循环等待
	S = S-1;          //如果资源足够，占用一个资源
}
void signal(int S){   //相当于“退出区”
	S=S+1             //使用完资源后，释放资源
}
----
//===进程P_0:===
...
wait(S);              //进入区，申请资源
use_printer_source;   //临界区，访问资源
signal(S);            //退出区，释放资源
...
```

整型信号量的缺陷是存在“忙等”问题，因此“**记录型信号量**被提出”，即用记录型数据结构表示的信号量
```C++
//记录型信号量的定义
typedef struct {
	int value;            //剩余资源数
	struct process *L;    //等待队列
} semaphore;
//某进程需要使用资源时，通过 wait 原语申请
void wait (semaphore S){
	S.value--;
	if (S.value <0) // 如果剩余资源数不够，使用block原语使进程进入阻塞态
		block (S.L);// 并把进程挂到信号量S的等待队列中
}
// 某进程完成使用资源时，通过 signal 原语释放
void signal (semaphore S){
	S.value++;
	if (S.value <= 0)// 如果释放资源后，还有别的进程等待资源
		wakeup(S.L); // wakeup原语可以唤醒等待队列队首进程，该进程从阻塞变为就绪
}
```
如果`S.value`的值为正数，说明当前资源有剩余；如果为负数，负数的绝对值就是当前等待资源的进程数。

对信号量S的一次P操作意味着进程**请求一个单位的该类资源**，因此S.value--，表示空闲资源数减一。当S.value<0时表示该类资源已经分配完毕，因此进程应该**调用block原语进行自我阻塞**（当前进程从**运行态->阻塞态**），主动放弃处理机，并插入该类资源的等待队列S.L中。因此记录型信号量机制上**遵循了“让权等待”原则**，不会出现“忙等”现象

对信号量S的一次V操作意味着进程**释放一个单位的该类资源**，因此执行S.value++，表示空闲资源数加一。若加1后仍是S.value<=0，表示依然有进程在等待该类资源。因此，应**调用wakeup原语唤醒等待队列中的第一个进程**（被唤醒进程从**阻塞态->就绪态**）
##### 实现进程互斥
1. 分析并发进程的关键活动，划定临界区
2. 设置**互斥信号量**mutex，**初值为1**，mutex作为一种资源信号量，可以认为是访问临界资源的名额
3. 在进入区P(mutex)--申请资源
4. 在退出区V(mutex)--释放资源
```C++
semaphore mutex=1;    // 初始化信号量
P1(){
	...
	P(mutex);         // 使用临界资源前加锁
	critical_section;
	V(mutex);         // 使用临界资源后解锁
	...
}
P2(){
	...
	P(mutex);
	critical_section;
	V(mutex);
	...
}
```

- 对**不同的临界资源**需要设置不同的互斥信号量
- **P、V操作必须成对出现**。缺少P(mutex)就不能保证临界资源的互斥访问；缺少V(mutex)会导致资源永不被释放，等待进程永不被唤醒
##### 实现进程同步
进程同步会出现问题是**因为进程代码执行的异步性是无法预知的**，进程内的代码具有前后关系，但是**进程间的代码先后执行顺序却无法预知**。因此，如果进程之间的代码执行先后有制约关系，就可能出现问题。如何**让本来异步并发的进程相互配合，有序推进**，这就是进程同步需要解决的问题。

1. 分析何处需要实现“同步关系”，即必须保证“一前一后”执行的两个操作
2. 设置同步信号量S，初始值为0
3. 在前操作之后执行V(S)
4. 在后操作之前执行P(S)

信号量S代表某种资源，刚开始是没有资源的，只有当P1生产这种资源后，P2才可以使用
```C++
semaphore S=0;

P1(){
	code1;
	code2;
	V(S);
	code3;
}
P2(){
	P(S);
	code4;
	code5;
	code6;
}
```
若先执行到V(S)操作，则S++后S=1.之后当执行到P(S)操作时，由于S=1，表示有可用资源，会执行S--，S的值变回0，P2进程不会执行block原语，而是继续执行code4

若先执行到P(S)操作，此时S=0，S--后S=-1，此时没有可用资源，会执行block原语将P2变为阻塞态。只有当P1执行到V(S)后，S++，使S变回0，由于此时有进程在该信号量的阻塞队列中，因此会在V操作中执行wakeup原语，唤醒P2进程，这样P2就可以继续执行代码4
##### 实现进程的前驱关系
![[实现进程的前驱关系.png]]
总结：
- 互斥问题，信号初始量设为1
- 同步问题，信号初始量设为0
- 前驱问题就是解决多级同步问题
### 2.4.3 典型的进程互斥同步案例
#### 2.4.3.1 生产者-消费者问题
- 系统中有一组生产者进程和一组消费者进程，生产者进程每次生产一个产品放入缓冲区，消费者进程每次从缓冲区中取出一个产品并使用
- 生产者、消费者共享一个初始为空、大小为n的缓冲区
- 只有缓冲区没满时，生产者才能把产品放入等待区，否则必须等待
- 只有缓冲区不空时，消费者才能从中取出产品，否则必须等待
- 缓冲区临界资源，各进程必须互斥地访问
$$
\begin{align} 
同步关系：\\
缓冲区没满 & \to生产者生产 \\
缓冲区没空 & \to消费者消费 \\
\end{align}
$$
思路分析：
1. 关系分析，找出各个线程之间的同步和互斥关系
2. 整理思路，根据各进程的操作流程确定P、V操作的大致顺序

```C++
semaphore mutex = 1; // 互斥信号量，实现对缓冲区的访问
semaphore empty = n; // 同步信号量，表示空闲缓冲区的数量
semaphore full  = 0; // 同步信号量，表示产品数量，即非缓冲区数量

producer(){
	while(1){
		produce();
		P(empty);    // 消耗一个空闲缓冲区
		P(mutex);
		putProductToBuffer();
		V(mutex);    
		V(full);     // 增加一个产品
	}
}

consumer(){
	while(1){
		P(full);     // 消耗一个产品
		P(mutex);
		getProducts();
		V(mutex);
		V(empty);    // 增加一个空闲缓冲区
		consumeProduct();
	}
}
```

>[!warning] 如果调换相邻的P、V操作
>假设缓冲区已经放满产品，empty=0，full=n
>则生产者进程先执行P(mutex)，再执行P(empty)，由于已经没有空闲空间，一次生产者被阻塞。由于生产者阻塞，因此切换回消费者进程执行P(mutex)，由于mutex=0，即生产者还没释放对临界资源的锁，因此消费者也被阻塞
>这就造成了生产者等待消费者释放空闲区，而消费者又等待生产者释放临界区的情况，生产者和消费者循环等待被对方唤醒，出现死锁
#### 2.4.3.2 多生产者-多消费者问题
- 有多个生产者A，B，C，多个消费者a，b，c
- 每个消费者都有消费偏好，比如a只消费A的产品
- 只有一个缓冲区，每次只能容纳一个产品

**互斥关系**：对缓冲区的访问需要互斥进行
**同步关系**
- A将$\alpha$放入缓冲区后，a才能取出
- B将$\beta$放入缓冲区后，b才能取出
- 只有缓冲区为空，A或B才能放入产品
![[多生产者消费者.png]]
```C++
semaphore mutex = 1;
semaphore alpha = 0;
semaphore beta  = 0;
semaphore cache = 1;

A(){
	while(1){
		produce_alpha();
		P(cache);
		//===critical section====
		P(mutex);
		put_to_cache();
		V(mutex);
		//=======================
		V(alpha);
	}
}

B(){
	while(1){
		produce_beta();
		P(cache);
		//===critical section====
		P(mutex);
		put_to_cache();
		V(mutex);
		//=======================
		V(beta);
	}
}

a(){
	while(1){
		P(alpha);
		//===critical section====
		P(mutex);
		get_alpha();
		V(mutex);
		//=======================
		V(cache);
		consume_alpha();
	}
}

b(){
	while(1){
		P(beta);
		//===critical section====
		P(mutex);
		get_beta();
		V(mutex);
		//=======================
		V(cache);
		consume_beta();
	}
}
```

本例中，即使不设置mutex信号量也不会出现同时访问临界区的现象。原因在于，本例中的缓冲区大小为1，alpha、beta、cache三个同步信号量最多只有一个是1，因此任何时刻，最多只有一个进程的P操作不会被阻塞，并顺利进入临界区。**写上mutex肯定不会出错，不写可能会出错。**
从**事件**的角度分析，可以将上述四对“进程行为的前后关系”抽象为一对“事件的前后关系”
$$
Cache变空\to 放入产品
$$
“Cache变空”事件可能由a或b引发，“放入产品”可能由A或B执行，这样的话就可以用一个同步信号量解决。
#### 2.4.3.3 吸烟者问题
- 一个系统有**三个抽烟者进程**和**一个供应者进程**
- 每个抽烟者不停地卷烟并抽掉它，但是要卷一支烟需要三种材料：烟草，纸、胶水
- 三个抽烟这中，一个拥有烟草，一个有纸，一个有胶水
- 供应者无限地供应三种材料，供应者每次将两种材料放桌上
- 拥有剩下那种材料的抽烟者卷一支烟抽掉它，并给供应者一个信号告诉它完成了，供应者就会放另外两种材料在桌上，这个过程一直重复（让三个抽烟者轮流地抽烟）
- 该问题也属于是“生产者-消费者问题”，更详细地，是“可生产多种产品的单生产者-多消费者”

分析：
- 互斥关系 桌子是容量为1的缓冲区，我们将每次两种物品看作是一种组合，则一共有三种组合，需要互斥访问。
- 同步关系
	- 桌上有组合一，则第一个抽烟者取走东西
	- 桌上有组合二，则第二个抽烟者取走东西
	- 桌上有组合三，则第三个抽烟者取走东西
	- 发出完成信号，则供应者将下一个组合放在桌上
- 设置信号量
	- 互斥信号量mutex一般为1
	- 同步信号量看对应资源的初始值是多少
![[吸烟者问题.png]]
```C++
semaphore offer1 = 0;
semaphore offer2 = 0;
semaphore offer3 = 0;
semaphore finish = 0; // 抽烟者是否完成
int i = 0; // 实现让三个抽烟者轮流抽烟
provider(){
	while(1){
		if(i==0){
			put_offer1_desk();
			V(offer1);
		} else if(i==1){
			put_offer2_desk();
			V(offer2);
		} else if(i==2){
			put_offer3_desk();
			V(offer3);
		}
		i = (i+1) % 3;
		P(finish);
	}
}

smoker1(){
	while(1){
		P(offer1);
		从桌上拿走组合一；卷烟；抽掉；
		V(finish);
	}
}
smoker2(){
	while(1){
		P(offer2);
		从桌上拿走组合二；卷烟；抽掉；
		V(finish);
	}
}
smoker3(){
	while(1){
		P(offer3);
		从桌上拿走组合三；卷烟；抽掉；
		V(finish);
	}
}
```
#### 2.4.3.4 读者写者问题
- 现有读者和写者两组并发进程，共享一个文件
- 当两个或两个以上的读进程同时访问共享数据不会产生副作用
- 但是当某个写进程和其他读/写进程同时访问共享数据则可能导致数据不一致的问题
- 因此要求
	- 允许多个读者同时对文件执行读操作
	- 同一时间，只允许一个写者往文件中写信息
	- 任一写者在完成写操作之前不允许其他读者/写者工作
	- 写者执行写操作前，应让已有的读者和写者全部退出

问题分析：
- 互斥关系：写与写，写与读

```C++
semaphore rw = 1;    //实现共享文件的互斥访问
int count = 0;       //记录当前有几个读进程在访问文件
semaphore mutex = 1; //用于保证对count变量的互斥访问
writer(){
	while(1){
		P(rw); // 写之前加锁
		write_to_file();
		V(rw); // 写之后解锁
	}
}

reader(){
	while(1){
		P(mutex);
		if(count == 0) // 由第一个读进程负责申请读文件
			P(rw);     // 读之前加锁
		count++;       // 访问文件的读进程数加一
		V(mutex);
		read_from_file();
		P(mutex);
		count--;       // 访问文件的读进程数减一
		if(count == 0) // 由最后一个读进程负责释放文件
			V(rw);     // 读完解锁
		V(mutex);
	}
}
```
上面这种实现方式是读进程优先的，只要有读进程在读，写进程就必须一直阻塞等待，可能“饿死”。
进一步改进：
```C++
semaphore rw = 1;    //实现共享文件的互斥访问
int count = 0;       //记录当前有几个读进程在访问文件
semaphore mutex = 1; //用于保证对count变量的互斥访问
semaphore w = 1;     //用于实现写优先
writer(){
	while(1){
		P(w);
		P(rw); // 写之前加锁
		write_to_file();
		V(rw); // 写之后解锁
		V(w);
	}
}

reader(){
	while(1){
		P(w);
		P(mutex);
		if(count == 0) // 由第一个读进程负责申请读文件
			P(rw);     // 读之前加锁
		count++;       // 访问文件的读进程数加一
		V(mutex);
		V(w);
		read_from_file();
		P(mutex);
		count--;       // 访问文件的读进程数减一
		if(count == 0) // 由最后一个读进程负责释放文件
			V(rw);     // 读完解锁
		V(mutex);
	}
}
```
这种算法中，在进入连续多个读进程可以同时读文件；写者和其他进程不能同时访问文件；写者不会饥饿，但也不是真正的“写优先”，而是相对公平地先来先服务原则
#### 2.4.3.5 哲学家进餐问题
- 一张圆桌上坐着5位哲学家，每两个哲学家之间有一只筷子，桌子的中间是一碗米饭
- 哲学家要么思考，要么进餐，思考时不会影响他人
- 只有当哲学家饥饿时，才试图拿起左、右两根筷子（一根一根拿起）
- 如果筷子在别人手上，则需要等待，只有同时具有两根筷子才能吃饭
- 吃完后放下筷子，继续思考

问题分析：
- 互斥关系：5个哲学家进程与左右邻居对其中间筷子的访问是互斥的
- 这个问题中只有互斥关系，但是与前面问题不同的是，每个哲学家进程需要同时持有两个临界资源才能开饭。如何避免临界资源分配不当造成死锁现象，是该问题的重点
- 信号量设置：定义互斥信号量数组，实现对5个筷子的互斥访问。并对哲学家按0-4编号，哲学家i左侧的筷子编号为i，右侧的筷子编号为(i+1)%5
```C++
semaphore chopstick[5]={1,1,1,1,1};
P_i(){  // i号哲学家进程
	while(){
		P(chopstick[i]);       // 拿左筷子
		P(chopstick[(i+1)%5]); // 拿右筷子
		eat();
		V(chopstick[i]);       // 放左筷子
		V(chopstick[(i+1)%5]); // 放右筷子
		thinking();
	}
}
```
如果5个哲学家都并发地拿起了自己左手边的筷子，则每位哲学家都循环等待右边的人放下筷子，就会发生**死锁**现象
##### 如何防止死锁的发生
1. 对哲学家进程施加一些限制条件，比如最多允许四个哲学家同时进餐。这样可以至少保证有一个哲学家是可以拿到左右两支筷子
2. 要求奇数号的哲学家先拿左边的筷子，然后再拿右边的筷子，而偶数号哲学家刚好相反。这种方法可以保证如果相邻两个奇数号的哲学家都想吃饭，那么只有其中一个可以拿起第一支筷子，另一个直接阻塞，这就避免了占有一支筷子再等待另一支筷子的情况
3. 仅当一个哲学家左右两支筷子都可用时，才允许他抓起筷子。且各哲学家拿筷子这件事必须互斥地执行。这就保证了即使一个哲学家在拿筷子拿到一半被阻塞，也不会有别的哲学家尝试拿筷子。如此，当正在干饭的哲学家吃完后，被阻塞的哲学家就可以继续获得等待的筷子
```C++
semaphore chopstick[5]={1,1,1,1,1};
semaphore mutex = 1; // 互斥地取筷子
P_i(){  // i号哲学家进程
	while(){
		P(mutex);
		P(chopstick[i]);       // 拿左筷子
		P(chopstick[(i+1)%5]); // 拿右筷子
		V(mutex);
		eat();
		V(chopstick[i]);       // 放左筷子
		V(chopstick[(i+1)%5]); // 放右筷子
		thinking();
	}
}
```
这种实现方式虽然不能保证只有两边筷子都可用才允许哲学家拿筷子，但是总可以保证哲学家即使拿起一支筷子进入阻塞，在等待当前吃饭的哲学家放下筷子后，可以重新获得缺失的筷子
### 2.4.4 管程
#### 2.4.4.1 定义和基本特征
信号量机制存在编写程序困难、易出错的问题。管程就是一种机制，可以让程序员写代码时不用再细心地设计PV操作。

管程是一种特殊的软件模块，有以下部分组成：
- 局部于管程的**共享数据**说明
- 对该数据结构进行操作的**一组过程**
- 对局部于管程的共享数据设置初始值的语句
- 管程有一个名字

管程的基本特征：
- 局部于管程的数据只能被局部于管程的过程所访问
- 一个进程只有通过调用管程内的过程才能进入管程访问共享数据
- **每次仅允许一个进程在管程内执行某个内部过程**

```C++
monitor ProducerConsumer
	condition full, empty;  // 条件变量用来实现同步
	int count = 0;          // 缓冲区中的产品数
	void insert(Item item){ // 把产品放入缓冲区
		if(count == N)
			wait(full);
		count++;
		insert_item(item);
		if(count == 0)
			signal(empty);
	}
	Item remove(){          // 从缓冲区取出一个产品
		if(count == 0)
			wait(empty);
		count--;
		if(count == N-1)
			signal(full);
		return remove_item();
	}
end monitor

producer(){ // 生产者进程
	while(1){
		item = 生产一个产品;
		ProducerConsumer.insert(item);
	}
}
consumer(){ // 消费者进程
	while(1){
		item = ProducerConsumer.remove();
		消费产品item;
	}
}
```
由编译器负责实现各进程互斥地进入管程中的过程
管程中可以设置条件变量和等待/唤醒操作以解决同步问题
##### 用管程解决生产者消费者问题
1. 在管程中定义共享数据（如生产者消费者问题的缓冲区）
2. 需要在管程中定义用于访问这些共享数据的“入口”，即一些函数（如生产者消费者问题中，可以定义一个函数用于将产品放入缓冲区，再定义一个函数用于从缓冲区取出产品）
3. **只能通过特定的“入口”才能访问共享数据**
4. 管程中有很多“入口”，但是**每次只能开放其中一个“入口”**，并且只能让一个进程/线程进入（如生产者消费者问题中，各进程需要互斥地访问缓冲区。管程的这种特性即可保证一个时间段最多只有一个进程在访问缓冲区。注意***这种互斥特性是由编译器负责实现的，无须程序员关心***）
5. 可在管程中设置**条件变量**及**等待/唤醒操作**以解决同步问题。可以让一个进程/线程在条件变量上等待（**此时，该进程应该先释放管程的使用权，也就是让出“入口”**）；可以通过唤醒操作将等待在条件变量上的进程/线程唤醒
6. 程序员可以用某种特定的语法定义一个管程，之后其他程序员就可以使用这个管程提供的特定的“入口”方便地实现进程同步/互斥
### 2.4.5 死锁
#### 2.4.5.1 死锁的概念
>在并发环境下，各进程因竞争资源而造成的一种**互相等待对方手里的资源，导致各进程都阻塞，都无法向前推进的现象**，就是“死锁”。发生死锁后若无外力干涉，这些进程都将无法向前推进

- 死锁：各进程互相等待对方手里的资源，导致各进程都阻塞，都无法向前推进的现象
	- 一定处于阻塞态
- 饥饿：由于长期得不到想要的资源，某进程无法向前推进
	- 可能是阻塞态，也可能是就绪态
- 死循环：某进程执行过程中一直跳不出某个循环的现象。有时是因为程序逻辑问题，有时是程序员故意为之
	- 可以上处理机运行，即运行态，只不过无法像预期那样推进

##### 死锁产生的四个必要条件
- **互斥条件**：只有对必须互斥使用的资源的争抢才会导致死锁（如哲学家的筷子、打印机设备）。像内存、扬声器这样可以让多个进程使用的资源是不会导致死锁的（因为进程不用阻塞等待这种资源）
- **不剥夺条件**：进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放
- **请求和保持条件**：进程**已经保持了至少一个资源**，但又提出了**新的资源请求**，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源**保持**不放
- **循环等待条件**：存在一种进程资源的**循环等待链**，链中的每一个进程已获得的资源同时被下一个进程所请求（循环等待是**必要不充分条件**，资源等待链中某个节点可以有多个同类资源，只是某个资源在等待链中；但是**如果每类资源只有一个，此时循环等待就成了充要条件**）
##### 死锁发生的时机
1. 对系统资源的竞争。各进程对不可剥夺资源的竞争可能会引起死锁，对可剥夺资源（CPU）的竞争不会引起死锁
2. 进程推进顺序非法。请求和释放资源的顺序不当会导致死锁。
	- 例如，并发执行的程序P1、P2分别申请的资源被对方占有而阻塞，从而引发死锁
3. 信号量的使用不当也会造成死锁。
	- 生产者消费者问题中，如果实现互斥的P操作在实现同步的P操作之前，九可能导致死锁
	- 可以把互斥信号量、同步信号量也看作是一种抽象的系统资源
总之，对不可剥夺资源的不合理分配，可能导致死锁
##### 死锁的处理策略
1. 预防死锁。破坏死锁产生的四个必要条件中的一个或多个
2. 避免死锁。用某种方式防止系统进入不安全状态，从而避免死锁（银行家算法）
3. 死锁的检测和解除。允许死锁发生，不过操作系统会负责检测出死锁的发生，然后采取措施解决死锁
#### 2.4.5.2 预防死锁
##### 破坏互斥条件
互斥条件：只有对必须互斥使用的资源的争抢才会导致死锁
如果把只能互斥使用的资源改造成为允许共享使用，则系统就不会进入死锁状态。比如SPOOLing技术，操作系统可以采用SPOOLing技术把独占设备在逻辑上改造成共享设备。比如，用SPOOLing技术将打印机改造为共享设备。
![[SPOOLing技术.png]]
使用了SPOOling技术后，在各进程看来，自己对打印机资源的使用请求立即就被接收处理了，不需要再阻塞等待。

**但是**，并不是所有的资源都可以改造成可共享使用的资源。并且为了系统安全，很多地方必须保护这种互斥性。因此，**很多时候都无法破坏互斥条件**
##### 破坏不剥夺条件
不剥夺条件：进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放
- 方案一：当某个进程请求新的资源得不到满足时，他必须立即释放保持的所有资源，待以后需要时再重新申请。即使某些资源尚未使用完，也需要主动释放，从而破坏不可剥夺性
- 方案二：当某个进程需要的资源被其他进程所占有时，可由操作系统协助，将想要的资源强行剥夺。这种方式一般需要考虑各进程的优先级
	- 比如：剥夺调度方式，就是将处理机资源强行剥夺给优先级更高的进程使用
- 该策略的缺点：
	- 实现起来比较复杂
	- 释放已获得的资源可能造成前一阶段的工作失效。因此这种方法一般只适用于易保存和恢复状态的资源，如CPU
	- 反复申请和释放资源会增加系统开销，降低系统的吞吐量
	- 若采用方案一，意味着只要暂时得不到某个资源，之前获得的那些资源九都需要放弃，以后再重新申请。如果一直发生这种情况，就会导致进程饥饿
##### 破坏请求和保持条件
请求和保持条件：进程**已经保持了至少一个资源**，但又提出了**新的资源请求**，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源**保持**不放
- 可以采用**静态分配方法**，即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不让其运行。一旦运行，这些资源就一直归其所有，该进程就不会再请求别的任何资源
- 实现虽然简单，但是有明显缺点
	- 有些资源可能只需要很短的使用时间，因此如果某个进程的整个运行周期都一直保持所有资源，就会造成严重的资源浪费，**资源利用效率极低**。该策略也可能**导致某些进程饥饿**
##### 破坏循环等待条件
循环等待条件：存在一种进程资源的循环等待链，链中的每一个进程已获得的资源同时被下一个进程所请求
- 可采用**顺序资源分配法**。首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源（编号相同的资源）必须一次申请完
- 原理分析：一个进程只有已经占有小编号的资源时，才有资格申请更大编号的资源。按此规则，持有更大编号资源的进程不可能逆向申请小编号资源，从而不会产生循环等待现象
- 该策略的**缺点**
	- 不方便增加新的设备，因为可能需要重新分配所有的编号
	- 进程实际使用资源的顺序可能和编号递增顺序不一致，会导致资源浪费
	- 必须按规定次序申请资源，用户变成麻烦
#### 2.4.5.3 避免死锁
##### 安全序列
- 假设手中有100亿资金，有三个企业A，B，C来借款
- 如果借给企业的钱达不到企业提出的最大要求，则不管之前借了多少钱都会打水漂
- 刚开始，A、B、C分别借了20、10、30

|     | 最大需求 | 已借走 | 最多还会借 |
| :-: | :--: | :-: | :---: |
|  A  |  70  | 20  |  50   |
|  B  |  40  | 10  |  30   |
|  C  |  50  | 30  |  20   |
- 假设现在A还想在借30亿，如果借

|     | 最大需求 |   已借走    | 最多还会借 |
| :-: | :--: | :------: | :---: |
|  A  |  70  | 20+30=50 |  20   |
|  B  |  40  |    10    |  30   |
|  C  |  50  |    30    |  20   |
则后续只剩下10亿，如果ABC都提出再借20亿，则无法满足任何一个企业，全部变成坏账
- 假设B想借20亿，如果借

|     | 最大需求 |   已借走    | 最多还会借 |
| :-: | :--: | :------: | :---: |
|  A  |  70  |    20    |  50   |
|  B  |  40  | 10+20=30 |  10   |
|  C  |  50  |    30    |  20   |
此时手里还有20亿，可以先把这20亿全部借给C，等C把钱还回来，手里就会有20+30=50亿，再把钱都借给A，A还钱后有70亿，最后再借给B。
所以给B借20亿是安全的，因为存在$C\to A\to B$这样的**安全序列**

- 安全序列，就是如果系统按照这种序列分配资源，则每个进程都可以顺利完成。只要能找到一个安全序列，系统就是安全状态，安全序列可能有多个
- 如果分配资源后，系统无法找到任何安全序列，系统就进入了**不安全状态**。这意味着之后**可能**所有进程都无法顺利的执行下去。当然，如果有进程提前归还了资源，那系统也**有可能重新回到安全状态**。但是在分配资源之前必须考虑到最坏情况
- 如果系统处于**安全状态**，就**一定不会发生死锁**；如果系统进入不安全状态，就可能发生死锁（处于不安全状态未必发生死锁，发生死锁一定在不安全状态）
- 因此在资源分配之前**预判这次分配是否导致系统进入不安全状态**，来决定是否答应资源分配请求。这是“银行家算法”的核心。

可以将单维度的“钱”，拓展为多维度的向量

|     |  最大需求   |   已借走   |  最多还会借  |
| :-: | :-----: | :-----: | :-----: |
| P0  | (7,5,3) | (0,1,0) | (7,4,3) |
| P1  | (3,2,2) | (2,0,0) | (1,2,2) |
| P2  | (9,0,2) | (3,0,2) | (6,0,0) |
| P3  | (2,2,2) | (2,1,1) | (0,1,1) |
| P4  | (4,3,3) | (0,0,2) | (4,3,1) |
资源总数$(10,5,7)$，剩余可用资源$(3,3,2)$
- 每次从头到尾依次检查当前资源数是否够最多会借资源数（不能包括已加入安全序列的进程）
	- 可以满足进程P1需求，将进程P1加入安全序列，并更新剩余可用资源数$(5,3,2)$
	- 可以满足进程P3需求，将进程P3加入安全序列，并更新剩余可用资源数$(7,4,3)$
	- 可以满足进程P0需求，将进程P0加入安全序列，并更新剩余可用资源数$(7,5,3)$
	- 可以满足进程P2需求，将进程P2加入安全序列，并更新剩余可用资源数$(10,5,5)$
	- 可以满足进程P4需求，将进程P4加入安全序列，并更新剩余可用资源数$(10,5,7)$

##### 银行家算法
- 一般的，假设系统中有n个进程，m种资源，每个进程在运行前声明对各种资源的最大需求数
- 则可以用一个$n\times m$的矩阵来表示所有进程对各种资源的最大需求数。称为最大需求矩阵$Max$，$Max[i,j]=k$表示进程$P_{i}$最多需要$k$个资源$R_{j}$。
- 同理，系统可以用一个$n\times m$的分配矩阵$Allocation$表示对所有进程的分配情况。
- $Mac-Allocation=Need$矩阵，表示各进程还需要多少各类资源。
- 还需要一个长度为$m$的一维数组$Availabel$表示当前系统中还有多少可用资源
- 某进程$P_{i}$向系统申请资源用一个长度为$m$的一维数组$Request_{i}$表示本次申请的各种资源量
- 银行家算法流程
	1. 如果$Request_{i}[j]\leq Need[i,j](0\leq j\leq m)$，转向2，否则出错
		- 因为它需要的资源数已经超过它所声明的最大值
	2. 如果$Request_{i}[j]\leq Availabel[i,j](0\leq j\leq m)$，转向3，否则表示尚无足够资源，$P_{i}$必须等待
	3. 系统试探着将资源分配给进程$P_{i}$，并修改相应数据
		- 并非真的分配，只是为了做出预判
		- $Availabe=Available-Request_{i}$
		- $Allocation[i,j]=Allocation[i,j]+Request_{i}[j]$
		- $Need[i,j]=Need[i,j]-Request_{i}[j]$
	4. 操作系统执行**安全性算法**，检查此次资源分配后，系统**是否处于安全状态**。若安全，才正式分配；否则，恢复相应数据，让进程阻塞
		1. 检查当前剩余可用资源是否满足某个进程的最大需求，如果可以，就把该进程加入安全序列，并把分配给该进程的资源全部回收
		2. 不断重复上述过程，看最后是否可以让所有进程都加入安全序列
#### 2.4.5.3 检测和解除
系统需要提供两个算法：**死锁检测算法**和**死锁解除算法**
##### 死锁检测
死锁的四个必要条件：互斥、不剥夺、请求且保持、循环等待
1. 在资源分配图中，找出既不阻塞又不是孤点的进程$P_{i}$
	- 即找出一条有向边与它相连，且该有向边对应资源的申请数量小于等于系统中已有空闲资源数量。如下图中，$R_{1}$没有空闲资源，$R_{2}$有一个空闲资源。若所有连接该进程的边均满足上述条件，则这个进程能继续运行直至完成，然后释放它所占有的所有资源
2. 消去它所有的请求边和分配边，使之成为孤立的节点。在下图中，$P_{1}$是满足这一条件的进程节点，于是将$P_{1}$的所有边消去
3. 进程$P_{i}$所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原来的阻塞进程可能变为非阻塞进程。在下图中，$P_{2}$就满足这样的条件。
4. 根据1、2中的方法进行一系列简化后，若能消去图中所有的边，则称该图是**可完全化简的**
5. **死锁定理**：如果某时刻系统的资源分配图是不可完全化简的，那么此时系统死锁
![[死锁检测.png]]
##### 死锁解除
并不是系统中所有的进程都是死锁状态，只有那些死锁检测算法化简后，还连着边的那些进程就是死锁进程

解除死锁的主要方法有：
1. 资源剥夺法。挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但是应放止被挂起的进程长时间得不到资源而饥饿
2. 撤销进程法（终止进程法）。强制撤销部分、甚至全部的死锁进程，并剥夺这些进程的资源。这种方法的优点是实现简单，但是付出的代价可能比较大。因为某些进程可能已经运行了很长时间，已经接近结束了，一旦终止就功亏一篑，以后可能要重头再来
3. 进程回退法。让一个或多个死锁进程回退到足以避免死锁的地步。这就要求系统要记录进程的历史信息，设置还原点。
4. 如何决定该对哪些进程动手
	1. 进程优先级
	2. 已经执行的时间
	3. 还要多久能完成
	4. 进程使用了多少资源
	5. 进程是交互式的还是批处理式的

# 3 内存
## 3.1 基础
### 3.1.1 什么是内存
内存可以存放数据。**程序执行之前需要放到内存中才能被CPU处理**，为了缓和CPU和硬盘之间的速度矛盾。
在多道程序环境下，系统内可能会有多个并发程序，也就是谁会有多个程序的数据同时放在内存中。那么，**如何区分各个程序中的数据放在什么地方**，就是设计内存机制主要需要考虑的问题。
内存给出的方案是将内存划分为若干个“存储单元”，给每个存储单元进行编址。

如何计算内存大小：
- 如果计算机“按字节编址”，则每个存储单元大小为1字节，即1B，8个二进制位。
- 如果字长为16位的计算机“按字编址”，则每个存储单元大小为一个字，即16个二进制位。
- $\text{内存大小}=\text{单元大小}\times\text{地址数}$
### 3.1.2 进程运行的基本原理
#### 3.1.2.1 写程序到程序运行
![[程序编译到运行.png]]
#### 3.1.2.2 地址装入的三种方式
1. 绝对装入
	1. 在编译时，如果知道程序将放到内存中的具体位置，编译程序将产生绝对地址的目标代码，装入程序按照装入模块中的地址，将程序和数据装入内存。
	2. **只适用于单道程序环境**，因为必须知道程序被装入的地址，而且在不同电脑中内存环境也不一样，不能迁移。
2. 静态重定向
	1. 又称可重定位装入。编译、链接后的装入模块的地址都是从0开始的，指令中使用的地址、数据存放的地址都是相对于起始地址而言的逻辑地址。可根据内存的当前情况，将装入模块装入到内存的适当位置。**装入时对地址进行“重定位”，将逻辑地址变换为物理地址**（地址变换是在**装入时一次完成**的）
	2. 静态重定位的特点是在一个作业装入内存中，**必须分配其要求的全部内存空间**；如果不能满足，就不能装入该作业。作业一旦进入内存后，**在运行期间不能再移动**，也不能再申请内存空间
3. 动态重定位
	1. 又称动态时装入。编译、链接后的装入模块的地址都是从0开始的。装入程序把装入模块装入内存后，并不会立即把逻辑地址转换为物理地址，而是**把地址转换推迟到程序真正要执行时才进行**。因此装入内存后所有的地址依然是逻辑地址。这种方式需要一个**重定位寄存器**支持
	2. 重定位寄存器存放装入模块存放的起始地址
	3. 并且可将程序分配到不连续的存储器中；在程序运行前只需要装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。**采用重定位时允许程序在内存中移动**
#### 3.1.2.3 链接的三种方式
1. 静态链接：程序运行之前，先将各个目标模块及他们之间所需的库函数链接成一个完整的可执行文件
2. 装入时动态链接：将各目标模块装入内存时，边装入边链接的链接方式
3. 运行时动态链接：程序执行时需要用到该目标模块时，才对它进行链接。优点**是便于修改和更新，便于实现对目标模块的共享**

## 3.2 内存管理的概念
### 3.2.1 内存的分配与回收
操作系统需要记录哪些内存区域已经被分配出去，哪些还空闲。当进程运行结束后要及时收回内存空间。当进程要运行时，如果多个内存地址都可以装入进程，该选择哪一个装入？这些都是操作系统要考虑的问题
### 3.2.2 内存空间的扩充
有的程序大小超过内存大小，但是却可以运行。显然运行前将程序全部载入内存是不可能的，所以操作系统需要提供一种虚拟技术来从逻辑上对内存空间进行扩充
### 3.2.3 地址转换
为了使编程更加方便，程序员写程序只需要关注指令、数据的逻辑地址。而逻辑地址到物理地址的转换（这个过程称为**地址重定位**）应该由操作系统负责
#### 三种地址转换的方式（同3.1.2.2）
1. 绝对装入
	1. 在编译时，如果知道程序将放到内存中的具体位置，编译程序将产生绝对地址的目标代码，装入程序按照装入模块中的地址，将程序和数据装入内存。
	2. **只适用于单道程序环境**，因为必须知道程序被装入的地址，而且在不同电脑中内存环境也不一样，不能迁移。
2. 静态重定向
	1. 又称可重定位装入。编译、链接后的装入模块的地址都是从0开始的，指令中使用的地址、数据存放的地址都是相对于起始地址而言的逻辑地址。可根据内存的当前情况，将装入模块装入到内存的适当位置。**装入时对地址进行“重定位”，将逻辑地址变换为物理地址**（地址变换是在**装入时一次完成**的）
	2. 静态重定位的特点是在一个作业装入内存中，**必须分配其要求的全部内存空间**；如果不能满足，就不能装入该作业。作业一旦进入内存后，**在运行期间不能再移动**，也不能再申请内存空间
3. 动态重定位
	1. 又称动态时装入。编译、链接后的装入模块的地址都是从0开始的。装入程序把装入模块装入内存后，并不会立即把逻辑地址转换为物理地址，而是**把地址转换推迟到程序真正要执行时才进行**。因此装入内存后所有的地址依然是逻辑地址。这种方式需要一个**重定位寄存器**支持
	2. 重定位寄存器存放装入模块存放的起始地址
	3. 并且可将程序分配到不连续的存储器中；在程序运行前只需要装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。**采用重定位时允许程序在内存中移动**
### 3.2.4 存储保护
进程不可以访问操作系统的数据空间，也不能随意访问其他进程的内存数据空间，只可以访问自己的那一段内存空间，不然会乱
#### 两种内存保护的方法
1. 方法一：在CPU中**设置一对上、下限寄存器**，存放进程的上下限地址。进程的指令要访问某个地址时，CPU要检查是否越界。
2. 方法二：采用**重定位寄存器**（又称**基址寄存器**）和**界地址寄存器**（又称**限长寄存器**）进行越界检查。重定位寄存器中存放的**起始物理地址**。界地址寄存器中存放的是进程的**最大逻辑地址**。

## 3.3 覆盖和交换
### 3.3.1 覆盖技术
覆盖技术的思想：将程序分为多个段（多个模块）。常用段常驻内存，不常用的段在需要时调入内存。
内存中分为一个**固定区**和若干个**覆盖区**。需要常驻内存的段放在固定区中，调入后就不再调出，除非运行结束；不常用的段放在覆盖区，需要时调入内存。
按照逻辑结构，将不可能同时被访问的程序段共享一个覆盖区
**必须由程序员声明覆盖**，操作系统自动完成覆盖。
**缺点**：对用户不透明，增加了用户的编程负担，用于早期的操作系统，现在很少用。
![[覆盖技术.png]]
**如图，程序中不可能同时被访问的程序段共享同一段覆盖区，覆盖区的大小取最大的。**
### 3.3.2 交换技术
交换技术的思想：内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中已具备某些运行条件的进程换入内存。（进程在内存与磁盘间动态调度）。就是上一章中的中级调度（内存调度），决定将哪个处于挂起状态的进程重新调入内存
交换技术需要考虑三个问题：
##### 应该在外存的什么位置保存换出的线程
在具有交换功能的操作系统中，通常把磁盘空间划分为**文件区**和**交换区**两部分。文件区主要存放文件，**主要追求存储空间的利用率**，因此对文件区空间的管理采用**离散分散方式**；交换区空间只占磁盘的小部分，**被换出的进程数据就存放在交换区**。由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理**主要追求换入换出速度**，因此通常对换区采用**连续分配方式**，即**对换区的I/O速度比文件区的更快**。
##### 什么时候交换
交换通常在许多进程运行且内存紧张时进行，而系统负荷降低就暂停。例如在许多进程运行时经常发生缺页，就说明内存紧张，此时可以换出一些进程；如果缺页率明显下降，就可以暂停换出。
##### 应该换出哪些进程
可以优先换出阻塞进程或者优先级较低的进程。但是为了防止优先级低的进程在被调入内存后很快又被调出，有的系统会考虑进程在内存的驻留时间，如果驻留时间比较短，不会换出进程。注意：PCB会常驻内存，不会被换出。
### 3.3.3 连续分配管理方式
这是内存空间的分配与回收的一种方式。连续分配指的是用户进程分配的必须是一个连续的内存空间，与之相对的是**非连续分配管理**。
#### 3.3.3.1 单一连续分配
在单一连续分配方式中，内存被分为系统区和用户区。系统区通常位于内存的低地址部分，用于存放操作系统相关数据，用户区用于存放用户进程相关数据。
**但是**，此种方式**内存中只能有一道用户程序**，用户程序占有整个用户区空间。

- 优点
	1. 实现简单
	2. **无外部碎片**
	3. 可以采用覆盖技术扩充内存
	4. 不一定需要内存保护
- 缺点
	1. 只能用于单用户、单任务的操作系统
	2. 有内部碎片（分配给某进程的内存区域有部分没有用上的地方）
	3. 存储器利用效率低
#### 3.3.3.2 固定分区分配
为了能在内存中装入多道程序，且程序之间不能相互干扰，于是将整个用户空间划分为**若干个大小固定的分区**，在**每个分区中只装入一道作业**，这样就形成了最早最简单的一种可运行多道程序的内存管理方式。
固定分区有两种分区方式，分区大小相等和大小不等。

- 分区大小相等：缺乏灵活性，但是很适合用于一台计算机控制多个相同对象的场合
- 分区大小不等：增加灵活性，可以满足大小不同的进程需求。根据常在系统中运行的作业大小情况进行划分（比如多个小分区、适量中分区、少量大分区）

操作系统需要建立一个**分区说明表**，来实现各个分区的分配和回收。每个表对应一个分区，通常按分区大小排序，每个表项包括对应分区的大小、起始地址、状态（是否被分配）。
- 优点
	- 实现简单
	- 无外部碎片
- 缺点
	- 当用户程序太大时，可能所有分区都不能满足需求，此时不得不采用覆盖技术来解决，但这又会降低性能
	- 会产生内部碎片，内存利用率低
#### 3.3.3.3 动态分区分配
也称为**可变分区分配**。这种分配方式不会预先划分内存分区，而是在进程表装入内存时，**根据进程大小动态建立分区**，并使分区的大小正好适合进程的需要。因此系统分区的大小和数量是可变的
##### 系统要使用什么样的数据结构记录内存的使用情况？
两种常用的数据结构：空闲分区表和空闲分区链
空闲分区表的每个表项对应一个空闲分区，表项包含区号、分区大小、起始地址等信息
空闲分区链每个分区的起始部分和末尾部分分别设置前向指针和后向指针。起始部分处还可以记录分区大小等信息
##### 当很多个空闲分区都能满足需求时，应该选择哪个分区进行分配？
把一个新进程装入内存时，需要按照一定的**动态分配算法**，从空闲分区表/链中选出一个分区给该作业。
##### 如何进行分区的分配和回收操作？

- 分配
	- 可以将某个空闲分区的一部分分配给新进程，修改空闲分区表项中的分区大小和起始地址即可，此时空闲分区数量不会减少
	- 如果刚好分配给一个空闲分区刚好完全使用，则在空闲分区表/链中删除对应的空闲分区项，此时空闲分区的数量减一
- 回收
	- 回收区后面有一个相邻的空闲分区，则将两个空闲分区合并为一个，修改表项中的分区大小和起始地址
	- 回收区前面有一个相邻的空闲分区，也是将两个空闲分区合二为一
	- 回收区的前后都有空闲分区，则将三个空闲分区合并为一个
	- 回收区的前后都没有空闲分区，在空闲分区表中增加一个对应的表项

注意，**各表项的顺序不一定按照地址递增顺序排序，具体的排序方式取决于动态分区算法**

动态分区没有内部碎片，但是有外部碎片
内部碎片，分配给某进程的内存区中，有部分没用上
**外部碎片**，内存中某些空闲分区由于太小而难以利用
如果内存中空闲空间的总和本来可以满足某进程的要求，但是由于进程需要一整块连续的内存空间，因此这些外部碎片不能满足进程的需求。

可以通过紧凑（compaction）技术来结局外部碎片：将所有占用进程的内存空间往低地址方向移动，将所有的空闲区都换到高地址部分，可以采用动态重定位方法。

### 3.3.4 动态分区分配算法
在动态分区分配方式中，如果有多个空闲分区都能满足需求时，应该选择哪个分区进行分配
#### 3.3.4.1 首次适应算法（First Fit）
- 基本思想：每次从低地址部分开始查找，找到第一个能满足大小的空闲分区
- 实现方法：空闲分区以地址递增排序。每次分配内存时顺序查找空闲分区表/链，找到大小能满足的第一个空闲分区
#### 3.3.4.2 最佳适应算法（Best Fit）
- 基本思想：由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是一整块连续空间。因此为了保证当大进程到来时可以有连续的大片空间，可以尽可能多地留下大片的空闲区，即优先使用更小的空闲区
- 实现方法：空闲分区按容量递增次序链接，每次分配内存时顺序查找空闲分区表/链，找到大小能满足要求的第一个空闲分区
- 缺点：每次都选最小的分区进行分配，会留下越来越多的、很小的、难以利用的内存块，因此这种方法会产生越来越多的外部碎片
- 优点：每次从头开始检索，每次都需要检索低地址的小分区，当思思之部分有更小的分区可以满足需求时，会更有可能用到低地址部分的小分区，也更可能把高地址部分的大分区保留下来
#### 3.3.4.3 最坏适应算法（Worst Fit）
- 又称最大适应算法（Largest Fit）
- 算法思想：为了解决最佳适应算法的问题——遗留太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后的剩余空闲区不会太小，更方便使用
- 实现方法：空闲分区按容量递减。每次分配内存顺序查找空闲分区链/表，找到大小能满足要求的第一个空闲分区
- 缺点：每次都选择最大分区进行分配，虽然可以让分配后留下的空闲区更大，更可用，但是这种方式会导致较大的连续空间被迅速用完。如果后续有大进程到达，就无内存分区可用了
#### 3.3.4.1 邻近适应算法（Next Fit）
- 算法思想：首次适应算法每次都是从链头开始查找的，这可能导致低地址部分出现很多小的空闲分区，而每次分配查找时都需要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就可以解决上述问题
- 实现方法：空闲分区以地址递增的顺序排列（可排成一个循环链表），每次分配从上次查找结束位置开始查找空闲分区链/表，找到大小可以满足要求的第一个空闲分区
- 缺点：邻近适应算法可能导致无论地址高低，空闲分区都有相同概率被使用，也就导致了高地址部分的大分区更可能被使用划分为小分区，最后导致无大分区可用
综合来看，**首次适应算法反而是比较好的**
### 3.3.5 非连续分配管理方式
有三种管理方式：基本分页存储管理、基本分段存储管理、段页式存储管理
#### 3.3.5.1 基本分页存储管理
将内存空间分为一个个大小相同的分区，每个分区就是一个页框。每个页框有一个编号，即“页框号”，**页框号从0开始**。（页框=页帧=内存块=物理块=物理页面）
将进程的逻辑地址空间也分为与页框大小相等的一个个部分，每个部分页称为一个“页”，每个页都有一个编号，即页号，也是从0开始
操作系统以页框为单位为各个进程分配内存空间。进程的每个页面放入一个页框中，进程的页面与内存的页框一一对应，各个页面不必连续存放，可以放入不相邻的各个页框中
操作系统通过页表记录每个进程的页面在内存的页框中存放的位置，页表通常存放在PCB中。
##### 计算页表项的大小
![[页表和页框的对应关系.png]]
假设某系统物理内存大小为4GB，页面大小为4KB，则每个页表项至少应该为多少字节
- 内存块大小=页面大小=$4KB$=$2^{12}B$
- $4GB$的内存会被分为$2^{32}/2^{12}=2^{20}$个内存块
- 内存块号的范围是$0\to 2^{20}-1$，至少需要$20bit$表示
- 20bit至少需要3B(24bit)表示
- 页号是隐含的，因此每个页表项占3B，存储整个页表需要至少$3(n+1)B$
页表项连续存放，因此页号可以是隐含的，不占用存储空间
第$i$个内存块的起始地址=$i\times\text{内存块大小}$
##### 通过页表实现逻辑地址到物理地址的转化
虽然进程的各个**页面是离散存放**的，但是**页面的内部是连续存放**的
如果要访问逻辑地址A，则
1. 确定逻辑地址A对应的“页号”P
2. 找到P号页面在内存中的起始地址（需要查页表）
3. 确定逻辑地址A的页内偏移量W
4. 逻辑地址A对应的物理地址=P号页面在内存中的起始地址+页内偏移量W

在某计算机系统中，页面大小为50B，某进程逻辑空间大小为200B，则逻辑地址110对应的页号、页内偏移是多少
- 该进程会被分为$200/50=4$个页面
- 第$i$号的逻辑起始地址为$50i$
- 110应该是在2号页面中，相对2号页面的起始地址100的偏移量是10
- 页面在内存中的起始地址+页内偏移量=实际的物理地址

$$
\begin{align}
页号&=逻辑地址\div 页面长度 \\
页内偏移量&=逻辑地址\ \%\ 页面长度
\end{align}
$$
通常计算机内部地址用二进制表示，页面大小一般也设计成2的整数幂，则计算机硬件可以快速地将逻辑地址拆分为（页号，页内偏移量）
![[计算机硬件分页.png]]
如果每个页面的大小为$2^{k}B$，用二进制表示逻辑地址，则末尾$k$位即为**页内偏移量**，其余部分为页号
#### 3.3.5.2 基本地址变换机构
基本地址变换机构可以借助进程的页表将逻辑地址转换为物理地址
通常会设置一个页表寄存器(PTR)，存放页表在内存中的起始地址F和页表长度M。
进程未执行时，页表的起始地址和页表长度放在PCB中，当进程被调度时，操作系统内核会把他们放到页表寄存器中
![[地址变换机构流程图.png]]
- 页表长度M，页表中有多少个页表项，即总共几个页
- 页表项长度，每个页表项占多大存储空间
- 页面大小L，一个页面占多大存储空间
$$
物理地址E=bL+W
$$
在分页存储管理（页式管理）的系统中，只要确定了每个页面的大小，逻辑地址结构就确定。因此，页式管理中地址是一维的，只要给出一个逻辑地址，系统就可以自动地算出页号、页内偏移量两个部分，并不需要告诉系统逻辑地址中，页内偏移量占多少位

理论上只需要3字节就可以表示内存块号的范围，但是为了方便页表的查询，会使用一个页表占更多的字节，使得每个页面恰好可以装下整数个页表项。这样每个页框就不会有剩余空间而造成页表项地址的不连续。
#### 3.3.5.3 具有快表的地址变换机构
这是基本地址变换机构的改进版本
快表，又称联想寄存器（Translation Lookaside Buffer），是一种**访问速度比内存快很多的高速缓存**（TLB不是内存），用来存放**最近访问的页表项的副本**，可以加速地址变换的速度。与此对应的内存中的页表称为**慢表**
![[快表查询流程图.png]]
1. CPU给出逻辑地址，由某个硬件计算出页号和页内偏移量，将页号与快表中的所有页号进行比较
2. 如果找到匹配的页号，说明要访问的页表项在快表中有副本，直接从中取出该页对应的内存块号，再将内存块号和页内偏移量拼接形成物理地址。因此如果快表命中，则只需要一次访存即可
3. 否则需要访问内存中的页表，找到对应表项得到页面存放的内存块号。因此如果快表没命中，就需要两次访存。（在找到页表项后，应同时将其存入快表，以便后续访问。但若快表已满，就需要按照一定算法对旧的快表进行更新）
由于查询快表的速度比查询页表的速度快很多，因此只要快表命中，就能节省大量时间。根据局部性原理，一般快表的命中率在90%以上
##### 局部性原理
**时间局部性**：如果执行了程序中的某条指令，那么不久后这条指令很可能再次执行；如果某个数据被访问过，不久之后该数据很可能再次被访问。（因为程序中存在大量的循环）
**空间局部性**：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元页很有可能被访问。（因为很多数据在内存中都是连续存放的）
#### 3.3.5.4 两级页表
##### 单级页表存在的问题
- 页表必须连续存放，因此当页表比较大时，需要占用很多个连续的页框
- 没有必要让整个页表常驻内存，因为一些进程在一段时间内可能只需要访问某几个特定的页面
##### 解决页表连续存放问题
所以，可以将页表进行二级分组，使每个内存块刚好可以存放一个分组，再为离散分配的页表建立一张页表，称为**页目录表**，或外层页表、顶层页表
![[二级页表示意图.png]]
二级页表虽然增加了一些内存占用，但是很好地**解决了页表连续占用的问题**
###### 二级页表的地址转换
1. 将地址结构按照逻辑地址拆分为三部分
2. 从PCB中读出页目录表始址，在根据一级页号查页目录表，找到下一级页表在内存中的位置
3. 根据二级页号查表，找到最终要访问的内存块号
4. 结合页内偏移量得到物理地址
##### 解决页表常驻内存问题
可以在需要访问页面时才把页面调入内存（虚拟存储技术）。可以在页表项中增加一个标志位，用于表示该页表是否已经调入内存。如果访问页面时发现没有调入内存，则产生缺页中断（内中断），然后将目标页面从外存调入内存。
#### 3.3.5.2 基本分段存储管理
与分页存储最大的区别就是离散分配时所分配地址空间的基本单位不同。
##### 分段
**进程的地址空间**：程序**按照自身的逻辑关系**划分为若干个段，每个段都有一个段名（在低级语言中，程序员按照段名来编程），每段从0开始编址
**内存分配规则**：以段为单位进行分配，**每个段在内存中占据连续空间**，但是各段之间可以不相邻
由于是按照逻辑功能划分各个段，用户编程更加方便，程序的可读性更高。在写程序时的段名会在编译后变为段号（0号段、1号段……）段名方便程序员编程

分段系统的逻辑地址由**段号**和**段内地址**（段内偏移量）所组成
- 段号的位数决定每个进程可以最多分为几个段
- 段内地址位数决定了每个段的最大长度
##### 段表
程序被分为多个段，各段离散地装入内存，必须建立一张段映射表，让程序可以在物理内存中找到各段存放位置。
![[段表示意图.png]]
1. 每个段对应一个段表项，其中记录了该段在内存中的起始位置（又称**基址**）和**段的长度**。段表比页表多个一个记录段长度的值，因为每个段长度不一样。
2. 每个段表项的长度是相同的
	1. 例如某系统按字节寻址，采用分段存储管理
	2. 逻辑地址结构：段号16位+段内地址16位，因此可采用16位即可表示最大段长
	3. 物理内存大小4GB（可以用$\log_{2}4GB=32$位表示整个物理内存空间）。所以基址需要32位。
	4. 因此可以让每个段表项占$16+32=48$位，即$6B$
	5. 由于段表项长度相同，因此段号可以是隐含的，不占存储空间。若段表的始址为M，则K号段对应的段表的存放地址为$M+K\times 6$
##### 地址变换
![[段表地址变换.png]]
##### 分段、分页管理对比
**页**是**信息的物理单位**，分页的主要目的是为了实现离散分配，提高内存利用率。分页仅仅是系统管理上的需要，完全是系统行为，对用户不可见
**段**是**信息的逻辑单位**，分段的主要目的是更好地满足用户需求。一个段通常包含着一组属于一个逻辑模块的信息。分段对用户是可见的，用户编程时需要显式地给出段名

分页的用户进程地址空间是一维的，程序员只需要给出一个记忆符就可以表示一个地址
分段的用户进程地址空间是二维的，程序员在标识一个地址时，既要给出段名，也要给出段内地址

**分段比分也更容易实现信息的共享与保护**
#### 3.3.5.3 段页式存储管理

|      | 优点                          | 缺点                                  |
| ---- | --------------------------- | :---------------------------------- |
| 分页管理 | 内存空间利用效率高，不会产生外部碎片，只有少量页内碎片 | 不方便按照逻辑模块实现信息的共享和保护                 |
| 分段管理 | 很方便按照逻辑模块实现信息共享和保护          | 如果段长过大，为其分配很大的连续空间会很不方便。段式管理会产生外部碎片 |
##### 段+页=段页式
将进程按逻辑模块分段，再将各段分页
再将内存空间分为大小相同的内存块
##### 段页式管理的逻辑地址结构
段号+页号+页内偏移量
![[段页式逻辑地址.png]]
段号的位数决定了每个进程最多有多少个段
页号的位数决定了每个段最多有多少个页
页内偏移量的位数决定了每个页的大小

以上图为例
段号16位，则每个进程最多可以有$2^{16}=64K$个段
页号4位，则每个段可以最多占有$2^{4}=16$个页
页内偏移量12位，则每个内存块的大小为$2^{12}=4KB$

段页式管理中，“分段”对用户是可见的，程序员编程需要显式地给出段号，段内地址。而将各段“分页”对用户是不可见的。系统会根据段内偏移量自动划分页号和页内偏移量。因此段页式管理的地址结构是二维的
![[段页式存储管理分段分页过程.png]]
每个段对应一个段表项，每个段表项由段号、**页面长度、页表存放块号**（页表起始地址组成）。每个段表项长度相等，段号是隐含的
每个页面对应一个页表项，每个页表项由页号、页面存放的内存块号组成。每个页表项长度相等，页号也是隐含的
##### 逻辑地址转换为物理地址
![[段页式逻辑地址转换.png]]
同样可以引入快表机构，以段号和页号为关键字查询快表，如果找到就直接访问最终的页面存放地址，此时仅需一次访存

## 3.4 虚拟内存